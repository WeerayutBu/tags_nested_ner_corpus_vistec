{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_sentence\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find filenames in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/module/data/vistec_corpus/data_raw/dataLot1/pct_wn_first_lot.csv\n",
      "/home/module/data/vistec_corpus/data_raw/datalot2/pct_600review_195530.csv\n",
      "/home/module/data/vistec_corpus/data_raw/datalot3/pct_600review_198387.csv\n",
      "/home/module/data/vistec_corpus/data_raw/dataLot1/ner_lot1_180520_num_word_192449_num_tag_21688.json\n",
      "/home/module/data/vistec_corpus/data_raw/datalot2/ner_lot2_180520_num_word_195530_num_tag_32232.json\n",
      "/home/module/data/vistec_corpus/data_raw/datalot3/ner_lot3_180520_num_word_198387_num_tag_31329.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_corpus    = '/home/module/data/vistec_corpus/data_raw/'\n",
    "Format_csv     = '**/*.csv'\n",
    "Format_json    = '**/*.json'\n",
    "\n",
    "filenames_csv  = [f for f in glob.glob(path_corpus+Format_csv, recursive=True)]\n",
    "filename_json  = [f for f in glob.glob(path_corpus+Format_json, recursive=True)]\n",
    "[print(f) for f in filenames_csv]\n",
    "[print(f) for f in filename_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the list of files name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file \n",
    "sentences      = []\n",
    "for filen_csv, filen_json in zip(filenames_csv, filename_json):\n",
    "    ## Check correct directory name and set name file to save\n",
    "    checklotdir_csv  = filen_csv.split('/')[-2]\n",
    "    checklotdir_json = filen_json.split('/')[-2]\n",
    "    save_file_name   = filen_json.split('/')[-2]\n",
    "    assert checklotdir_csv == checklotdir_json, \"Filename not match.\"\n",
    "\n",
    "    ## Load CSV file\n",
    "    datas_csv  = pd.read_csv(filen_csv)\n",
    "    \n",
    "    ## Load Json file \n",
    "    read_file = open(filen_json, \"r\")\n",
    "    datas_json = json.load(read_file)\n",
    "\n",
    "    ## Tags entities each sentence\n",
    "    for idx, data in enumerate(zip(datas_json, datas_csv['text_clean'])):\n",
    "        data_json = data[0]\n",
    "        data_csv  = data[1]\n",
    "        sentences.append([data_json, data_csv])\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sukishi |สา|ขา Mega Bangna |ตัว|ร้าน|จะ|อยู่|โซน| food walk |ค่ะ|จะ|อยู่|ใกล้|ๆ|กับ| star buck |เลย |ครั้ง|นี้|มา|ตรง|กับ|วัน|หยุด| อืัอ|หือ|ออ|คน|อย่าง|แน่น|เลย|ย |ต้อง|รอ|คิว|ค่ะ| วัน|นี้|รอ3|คิว |ก็|รอ|ไม่|นาน|แปป|เดียว |ตัว|ร้าน|ที่|สา|ขา|นี้|ถือ|ว่า|กว้าง|มาก|ๆ|เลย|ค่ะ| จัด|ร้าน|ดู|โปร่ง|โล่ง|สบาย|ด้วย |ช่วง|นี้|มี|เฮ|  |เพราะ|เค้า|ลด|รา|คา|สำ|หรับ|อา|หาร|หลาย|ๆ|ชุด|ค่ะ| ก็|จัด|มา1|ชุด |จำ|รา|คา|ไม่|ได้|ไม่|แน่|ใจ|ว่า| 799. |หรือ|เปล่า| อ้ะ|ะะ|หิว|มาก|ก็|จัด|ซะ|เลย|ย |เนื้อ|นุ่ม|มาก|อร่อย|ด้วย|คือ|ดี|คือ|ฟิน|นน|น |ยิ่ง|เป็น|เบ|คอน|ยิ่ง|อร่อย|เลย|ค่ะ| รส|ชาติ|หมู|และ|ความ|นุ่ม|ยก|ให้|สุ|กี้|ชิ|เลย |เครื่อง|ดื่ม |สั่ง|ชา|มะ|นาว|และ|โก|โก้|เฟรป|เป้|มา |โก|โก้|รส|ชาติ|ใช้|ได้|เลย|ค่ะ| แต่|หวาน|มาก|ไป|นิด|นึง| นึก|ถึง|ปิ้ง|ย่าง|นึก|ถึง| Sukishi |เลย|ค่ะ|ยก|ใจ|ให้|เลย'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_csv['ssg'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentence(data, text=None):\n",
    "    data = json.dumps(data)\n",
    "    data = json.loads(data)\n",
    "    \n",
    "    cl_text = data['text']\n",
    "    en_list = data['entities']\n",
    "    \n",
    "    if( text is None ):\n",
    "        text = cl_text\n",
    "    \n",
    "    Format = '{:<70} \\t\\t{:<20} {:<3}{:>5} <-> {:<20}'\n",
    "    print('Text:\\n\\t{}\\n'.format(text))\n",
    "    print(Format.format('\\ntext', 'type', 'No', 'start_idx', 'end_idx\\n'))\n",
    "    en_list = sorted(en_list, key=lambda x:(x['start_idx'], -x['end_idx']))\n",
    "    \n",
    "    for idx,entity in enumerate(en_list):\n",
    "        print(Format.format(entity['text'], entity['type'], idx, entity['start_idx'], entity['end_idx']), end=' ')\n",
    "        if(text != None ):\n",
    "            check_text = text[int(entity['start_idx']):int(entity['end_idx'])]\n",
    "            print('--{}--'.format(check_text),end='')\n",
    "            print()\n",
    "    print('\\n All entities : ',idx+1,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check json data by sent number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences No. 1\n",
      "Sukishi สาขา Mega Bangna ตัวร้านจะอยู่โซน food walk ค่ะจะอยู่ใกล้ๆกับ star buck เลย ครั้งนี้มาตรงกับวันหยุด อืัอหือออคนอย่างแน่นเลยย ต้องรอคิวค่ะ วันนี้รอ3คิว ก็รอไม่นานแปปเดียว ตัวร้านที่สาขานี้ถือว่ากว้างมากๆเลยค่ะ จัดร้านดูโปร่งโล่งสบายด้วย ช่วงนี้มีเฮ  เพราะเค้าลดราคาสำหรับอาหารหลายๆชุดค่ะ ก็จัดมา1ชุด จำราคาไม่ได้ไม่แน่ใจว่า 799. หรือเปล่า อ้ะะะหิวมากก็จัดซะเลยย เนื้อนุ่มมากอร่อยด้วยคือดีคือฟินนนน ยิ่งเป็นเบคอนยิ่งอร่อยเลยค่ะ รสชาติหมูและความนุ่มยกให้สุกี้ชิเลย เครื่องดื่ม สั่งชามะนาวและโกโก้เฟรปเป้มา โกโก้รสชาติใช้ได้เลยค่ะ แต่หวานมากไปนิดนึง นึกถึงปิ้งย่างนึกถึง Sukishi เลยค่ะยกใจให้เลย\n",
      "\n",
      "\n",
      "Json text\n",
      "Text:\n",
      "\tSukishi  สา ขา Mega Bangna  ตัว ร้าน จะ อยู่ โซน  food walk  ค่ะ จะ อยู่ ใกล้ ๆ กับ  star buck  เลย  ครั้ง นี้ มา ตรง กับ วัน หยุด  อืัอ หือ ออ คน อย่าง แน่น เลย ย  ต้อง รอ คิว ค่ะ  วัน นี้ รอ3 คิว  ก็ รอ ไม่ นาน แปป เดียว  ตัว ร้าน ที่ สา ขา นี้ ถือ ว่า กว้าง มาก ๆ เลย ค่ะ  จัด ร้าน ดู โปร่ง โล่ง สบาย ด้วย  ช่วง นี้ มี เฮ    เพราะ เค้า ลด รา คา สำ หรับ อา หาร หลาย ๆ ชุด ค่ะ  ก็ จัด มา1 ชุด  จำ รา คา ไม่ ได้ ไม่ แน่ ใจ ว่า  799.  หรือ เปล่า  อ้ะ ะะ หิว มาก ก็ จัด ซะ เลย ย  เนื้อ นุ่ม มาก อร่อย ด้วย คือ ดี คือ ฟิน นน น  ยิ่ง เป็น เบ คอน ยิ่ง อร่อย เลย ค่ะ  รส ชาติ หมู และ ความ นุ่ม ยก ให้ สุ กี้ ชิ เลย  เครื่อง ดื่ม  สั่ง ชา มะ นาว และ โก โก้ เฟรป เป้ มา  โก โก้ รส ชาติ ใช้ ได้ เลย ค่ะ  แต่ หวาน มาก ไป นิด นึง  นึก ถึง ปิ้ง ย่าง นึก ถึง  Sukishi  เลย ค่ะ ยก ใจ ให้ เลย\n",
      "\n",
      "\n",
      "text                          \t\ttype                 No start_idx <-> end_idx\n",
      "            \n",
      "Sukishi                        \t\trestaurant           0      0 <-> 7                    --Sukishi--\n",
      "Mega Bangna                    \t\tfacility:other       1     15 <-> 26                   --Mega Bangna--\n",
      "Mega                           \t\tloc:others           2     15 <-> 19                   --Mega--\n",
      "Bangna                         \t\tdistrict             3     20 <-> 26                   --Bangna--\n",
      "food walk                      \t\tloc:others           4     50 <-> 59                   --food walk--\n",
      "food                           \t\tloc:others           5     50 <-> 54                   --food--\n",
      "star buck                      \t\trestaurant           6     85 <-> 94                   --star buck--\n",
      "3                              \t\tcardinal             7    192 <-> 193                  --3--\n",
      "คิว                            \t\tunit                 8    194 <-> 197                  --คิว--\n",
      "1                              \t\tcardinal             9    388 <-> 389                  --1--\n",
      "ชุด                            \t\tunit                 10   390 <-> 393                  --ชุด--\n",
      "799                            \t\tcardinal             11   428 <-> 431                  --799--\n",
      "เบ คอน                         \t\tfood:ingredient      12   535 <-> 541                  --เบ คอน--\n",
      "สุ กี้ ชิ                      \t\trestaurant           13   595 <-> 604                  --สุ กี้ ชิ--\n",
      "สุ กี้                         \t\tfood:ingredient      14   595 <-> 601                  --สุ กี้--\n",
      "Sukishi                        \t\trestaurant           15   747 <-> 754                  --Sukishi--\n",
      "\n",
      " All entities :  16 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_no       = 1\n",
    "\n",
    "check_by_text = False\n",
    "text          = 'ประชาไท  17 ม.ค. 49 รายการเก็บตกจากเนชั่น'\n",
    "\n",
    "\n",
    "# Check by sentence number\n",
    "if(check_by_text == False):\n",
    "    \n",
    "    data = sentences[sent_no-1]\n",
    "    data_json = data[0]\n",
    "    data_csv  = data[1]\n",
    "    \n",
    "    print('Sentences No.', sent_no)\n",
    "    print(data_csv)\n",
    "    \n",
    "    print('\\n\\nJson text')\n",
    "    check_sentence(data_json)\n",
    "\n",
    "else:\n",
    "    for idx, data in enumerate(sentences):\n",
    "        data_json = data[0]\n",
    "        data_csv  = data[1]\n",
    "\n",
    "        # Check by text in the sentence\n",
    "        if(text in data_csv):\n",
    "            \n",
    "            print('Sentences No.', idx)\n",
    "            print(data_csv)\n",
    "            \n",
    "            print('\\n\\nJson text')\n",
    "            check_sentence(data_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:model] *",
   "language": "python",
   "name": "conda-env-model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
