{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "import os\n",
    "path = '/home/module/'\n",
    "os.chdir(path)\n",
    "\n",
    "import glob\n",
    "from collections                   import Counter\n",
    "from dataloader.dataloader_utils   import Dataloader, get_filename\n",
    "from tokenizer.word_tokenizer      import tokenizer_split_vistec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "from PATH.path_data import path_vistec_gdata        as path_data\n",
    "\n",
    "# Save dicts\n",
    "from PATH.path_data import path_vistec_gdicts       as path_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'batch_size_prepro' : 3000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter_tokens(data):\n",
    "    vocab = Counter()\n",
    "    for idx, batch in enumerate(data):\n",
    "        for sent in batch:\n",
    "            sent = tokenizer_split_vistec(sent)\n",
    "            vocab.update(sent)            \n",
    "    return vocab\n",
    "\n",
    "def get_counter_chars(data):\n",
    "    vocab = Counter()\n",
    "    for idx, batch in enumerate(data):\n",
    "        \n",
    "        #Update chars \n",
    "        for sent in batch:\n",
    "            vocab.update(list(sent))\n",
    "    return vocab\n",
    "\n",
    "def Sort_dict_freq(counter_dict, MINCOUNT=1):\n",
    "    Dict  = {(w,c) for w, c in counter_dict.items() if c >= MINCOUNT}\n",
    "    Dict  = sorted(Dict, key=lambda item: item[1], reverse=True)\n",
    "    Dict  = [w[0] for w in Dict]\n",
    "    return Dict\n",
    "\n",
    "def Save_vocab(path_name, Dict, Add_dict=None):\n",
    "    file   = open(path_name, 'w')\n",
    "    Format = '{}\\n'\n",
    "    \n",
    "    # Save add dict\n",
    "    if(Add_dict != None):\n",
    "        for dict_ in Add_dict:\n",
    "            file.writelines(Format.format(dict_))\n",
    "    \n",
    "    # Save dict\n",
    "    for dict_ in Dict:\n",
    "        file.writelines(Format.format(dict_))\n",
    "    file.close\n",
    "    \n",
    "def Save_logs(path_name, Dict):\n",
    "    file   = open(path_name, 'w')\n",
    "    Format = '{}\\n'\n",
    "    \n",
    "    # Save dict\n",
    "    for dict_ in Dict.items():\n",
    "        file.writelines(Format.format(dict_))\n",
    "    file.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict from training data src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/vistec_corpus/main_tags/data/\n"
     ]
    }
   ],
   "source": [
    "print(path_data['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.src  dev.trg  test.src  test.trg  train.src  train.trg\n"
     ]
    }
   ],
   "source": [
    "!ls {path_data['path']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load file name and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/vistec_corpus/main_tags/data/train.src']\n"
     ]
    }
   ],
   "source": [
    "Format_src     = '**/train.src'            # data\n",
    "filenames_src  = get_filename(path_data['path'], Format_src)\n",
    "data_src       = Dataloader(filenames_src, batch_size=params['batch_size_prepro'])\n",
    "\n",
    "counter_dict   = get_counter_tokens(data_src)    #Input data and tokenizer\n",
    "Dict           = Sort_dict_freq(counter_dict)\n",
    "\n",
    "Save_vocab(path_dicts['words'], Dict, ['pad','unk'])\n",
    "Save_logs(path_dicts['path']+'logs-word', counter_dict)\n",
    "print(filenames_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict from training data trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/vistec_corpus/main_tags/data/train.trg']\n"
     ]
    }
   ],
   "source": [
    "Format_trg     = '**/train.trg'            # data\n",
    "filenames_trg  = get_filename(path_data['path'], Format_trg)\n",
    "data_trg       = Dataloader(filenames_trg, batch_size=params['batch_size_prepro'])\n",
    "\n",
    "counter_dict  = get_counter_tokens(data_trg)    #Input data and tokenizer\n",
    "Dict          = Sort_dict_freq(counter_dict)\n",
    "\n",
    "Save_vocab(path_dicts['tags'], Dict, ['pad'])\n",
    "Save_logs(path_dicts['path']+'logs-tags', counter_dict)\n",
    "print(filenames_trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create chars dict from vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_trg  = get_filename(path_dicts['path'], 'words.txt')\n",
    "data_words     = Dataloader(filenames_trg, batch_size=params['batch_size_prepro'])\n",
    "\n",
    "counter_dict   = get_counter_chars(data_words)                        #Input data\n",
    "Dict           = Sort_dict_freq(counter_dict)\n",
    "\n",
    "Save_vocab(path_dicts['chars'], Dict, ['pad','unk'])\n",
    "Save_logs(path_dicts['path']+'logs-chars', counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3538 data/vistec_corpus/main_tags/dicts/words.txt\n",
      "42 data/vistec_corpus/main_tags/dicts/tags.txt\n",
      "144 data/vistec_corpus/main_tags/dicts/chars.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l {path_dicts['words']}\n",
    "!wc -l {path_dicts['tags']}\n",
    "!wc -l {path_dicts['chars']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clean\n",
    "24619 /home/model-structure/data/vistec_corpus/dicts_gclean/words.txt\n",
    "42 /home/model-structure/data/vistec_corpus/dicts_gclean/tags.txt\n",
    "211 /home/model-structure/data/vistec_corpus/dicts_gclean/chars.txt\n",
    "'''\n",
    "\n",
    "'''\n",
    "gclean\n",
    "24619 /home/model-structure/data/vistec_corpus/dicts_clean/words.txt\n",
    "394 /home/model-structure/data/vistec_corpus/dicts_clean/tags.txt\n",
    "211 /home/model-structure/data/vistec_corpus/dicts_clean/chars.txt\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:model] *",
   "language": "python",
   "name": "conda-env-model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
