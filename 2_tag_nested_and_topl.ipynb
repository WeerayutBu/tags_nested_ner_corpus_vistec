{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files\n",
      "/home/module/data/vistec_corpus/data_raw/dataLot1/pct_wn_first_lot.csv\n",
      "/home/module/data/vistec_corpus/data_raw/datalot2/pct_600review_195530.csv\n",
      "/home/module/data/vistec_corpus/data_raw/datalot3/pct_600review_198387.csv\n",
      "\n",
      "Json files\n",
      "/home/module/data/vistec_corpus/data_raw/dataLot1/ner_lot1_180520_num_word_192449_num_tag_21688.json\n",
      "/home/module/data/vistec_corpus/data_raw/datalot2/ner_lot2_180520_num_word_195530_num_tag_32232.json\n",
      "/home/module/data/vistec_corpus/data_raw/datalot3/ner_lot3_180520_num_word_198387_num_tag_31329.json\n"
     ]
    }
   ],
   "source": [
    "# This path for loading raw data from the VISTEC nested ner corpus.\n",
    "path_corpus          = '/home/module/data/vistec_corpus/data_raw/'\n",
    "Format_csv           = '**/*.csv'\n",
    "Format_json          = '**/*.json'\n",
    "\n",
    "filenames_csv        = [f for f in glob.glob(path_corpus+Format_csv, recursive=True)]\n",
    "filename_json        = [f for f in glob.glob(path_corpus+Format_json, recursive=True)]\n",
    "\n",
    "# Show all files to download\n",
    "print('CSV files')\n",
    "[print(f) for f in filenames_csv]\n",
    "\n",
    "print('\\nJson files')\n",
    "[print(f) for f in filename_json]\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the path to save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_levels = 8\n",
    "\n",
    "# # This setting for subtags nested ner.\n",
    "path_save            = '/home/module/data/vistec_corpus/nested_ner/subtags/'\n",
    "path_save_topl       = '/home/module/data/vistec_corpus/flatten_ner/subtags/'\n",
    "group                = False\n",
    "\n",
    "# # This setting for main tags nested ner.\n",
    "# path_save            = '/home/module/data/vistec_corpus/nested_ner/maintags/'\n",
    "# path_save_topl       = '/home/module/data/vistec_corpus/flatten_ner/maintags/'\n",
    "# group                = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags and save nested entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dataLot1 dataLot1\n",
      "pct_wn_first_lot.csv\n",
      "ner_lot1_180520_num_word_192449_num_tag_21688.json\n",
      "\n",
      " datalot2 datalot2\n",
      "pct_600review_195530.csv\n",
      "ner_lot2_180520_num_word_195530_num_tag_32232.json\n",
      "\n",
      " datalot3 datalot3\n",
      "pct_600review_198387.csv\n",
      "ner_lot3_180520_num_word_198387_num_tag_31329.json\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "temp_sentences   = []\n",
    "for filen_csv, filen_json in zip(filenames_csv, filename_json):\n",
    "    \n",
    "    # Check the file name to load and save.\n",
    "    checklotdir_csv   = filen_csv.split('/')[-2]\n",
    "    checklotdir_json  = filen_json.split('/')[-2]\n",
    "    save_file_name    = filen_json.split('/')[-2]\n",
    "    \n",
    "    assert checklotdir_csv == checklotdir_json\n",
    "    print('\\n',checklotdir_csv, checklotdir_json)\n",
    "    print('{}'.format(filen_csv.split('/')[-1]))\n",
    "    print('{}'.format( filen_json.split('/')[-1]))\n",
    "    \n",
    "    ## Create output files\n",
    "    sftags_nested_ner = open(path_save+save_file_name+'_nested.data', 'w')\n",
    "\n",
    "    ## Load CSV file\n",
    "    data_csv  = pd.read_csv(filen_csv)\n",
    "    \n",
    "    ## Load Json file \n",
    "    read_file = open(filen_json, \"r\")\n",
    "    data_json = json.load(read_file)\n",
    "    \n",
    "    ## Tags entities\n",
    "    for idx, datas in enumerate(zip(data_json, data_csv['ssg'], data_csv['text_clean'])):\n",
    "        \n",
    "        ## Remove pipe\n",
    "        datas = remove_pipe(datas[0],datas[1],datas[2])\n",
    "        \n",
    "        # Prepare data\n",
    "        entities            = datas['entities']\n",
    "        text                = datas['text']\n",
    "        token_idx_en        = get_all_entities_index(entities)\n",
    "        words_token         = token_en2words(token_idx_en, text)\n",
    "        words_tags_nested   = tags_nested(words_token, entities, max_levels, group=group)\n",
    "        words_tags_nested   = tags_bioes(words_tags_nested, max_levels)\n",
    "\n",
    "#         ## Save nested corpus ##\n",
    "        save_data(words_tags_nested, sftags_nested_ner, nested=True)\n",
    "        temp_sentences.append(words_tags_nested)\n",
    "\n",
    "sftags_nested_ner.close()\n",
    "# check_sentence(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save top-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcf = open(path_save_topl+'data.src', 'w')\n",
    "trgf = open(path_save_topl+'data.trg', 'w')\n",
    "\n",
    "for sent in temp_sentences:\n",
    "    \n",
    "    source = [token[0] for token in sent]\n",
    "    target = [token[1] for token in sent]\n",
    "    \n",
    "    srcf.writelines('|'.join(source)+'\\n')\n",
    "    trgf.writelines('|'.join(target)+'\\n')\n",
    "    \n",
    "srcf.close()\n",
    "trgf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check by sentence number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sent = 0\n",
    "ck_sent  = temp_sentences[idx_sent-1]\n",
    "for idx, sent in enumerate(ck_sent):\n",
    "    print(\"{:<5}\".format(idx), end='')\n",
    "    for token in sent:\n",
    "        [print('{:<15}\\t'.format(t), end='|') for t in token.split('|')]\n",
    "    print()       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:model] *",
   "language": "python",
   "name": "conda-env-model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
